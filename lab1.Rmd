---
title: "lab1"
author: "204814891_204169320"
date: "14 4 2020"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
library('maps')
library('ggplot2')
library('mapproj')
library('nycflights13')
library('readr')
library('dplyr')
library("nullabor")
```


We loaded a  bunch of libararys that will help us later.
this includes then nycflights13 library that has the following data frames that we will use:
- flights 
- airlines 
- airports 
- planes 
- weather


Q1 

After we did some exloration (by ourselfes) of the data, let's answer Q 1:

1.1)
Delayed flights fig:
   This graphic is telling a clear story, it is telling us the percent of flights that are delayed by more then 15 minutes, from Denver Colorado to other destinatinos in the US. 
   
Weekly Cycles fig:
  In this graph we have the numnber of lfihgts per day (from an unclear destination) and number of delayed flights per day in 2008. This shows us patterns of number of flights and delayed flight as a function of time. The nive thing is that it showes us patterns in regard to days of the week, time of the year and other unexpected events. 
  
  1.2)
Delayed flights fig:
  The story of this graph is conveyed, but it is a rather noisy story. although is easy to see that many flight are delayed, its not at all intuitive to understand the genreal pattern of flight delayes, in that sense the story is not convayed!

Weekly Cycles fig:
  We would say that this figure is very succeful in telling the story it like to! we see very well the weekly and yearly cycled of both flights and delayes!
  
  1.3)
Delayed flights fig:
  Looking at this graph we can see wekk that some destinations have high delay tendencies, however it is unclear to understatn the patterns of wich destinations tend to have delayes. It looks like we may have a slight corelation between the distance and delayes (fligths to ferther destinations may be abit later) but that surley is not anough to explain it since many far distances have low dealy rates. 
  Weekly Cycles fig:
Here too we have some new quastions that raise. First we don't know what flights are included in the data that made the graph!
Furthermore we see nice patterns in the number of flights, but the number of delayed flights seems like it might be more random, and is only loosly correlated to the number of flights, this begs the quastion of what is this correlated to (perhaps time of year).

1.4)
  Delays fligths fig:
Better choice collors would have been better, as in if all the delaye levels would be later-darker shades of the same collor it could be easier to understand the patterns and it would be easier to understand how high the delay tendancies are. Also we would make the thicknes of the line preportinet to either the  popularity of rute or of the destination, this would add important info!
  Weekly Cycled fig:
We would add multi year average info to the graph, this would give us refrence to see how many of the patternd we see are yearly cycles and how mane are a facotr of unexpected events of the time. Also we would make it clearer what data is being graphed (a perticular airport, nation wide etc).

--- 

Q2
seif a:
- first thing we need is the number of flights, and number of delade flights each day
and do some data proccesig to have the data rady for graphing.

```{r}
flights$date <- format(flights$time_hour, '%D')
# now we have some rows with missing data  witch will makes things ahrd for us, so we will remove all rows that contain NA values (for this grpah only) 
clean_flights <- na.omit(flights)
clean_flights$delayed <- ifelse(clean_flights$dep_delay > 15, 1, 0) # adding a binary delay value
# now we'll make a new data frame with number of fligths per day and another one for number of delayed per day
flights_per_day <- as.data.frame(table(factor(clean_flights$date))) 
colnames(flights_per_day) <- c("date", "flights")
delayes_per_day <- clean_flights %>% group_by(date) %>% summarise(Tot.delayed = sum(delayed))
colnames(delayes_per_day) <- c("date", "delayes")
data4graph <- merge(flights_per_day, delayes_per_day) #conecting both values to a single data frame
data4graph$date <- as.Date(data4graph$date, "%m/%d/%Y") # change the date to a date format
```
After setting up all the data in the way we want it, all we need to do is plot!

```{r}
ggplot(data4graph) + geom_line(aes(x=date,y= flights, color = 'All flights (schedualed for separtue)')) + 
  geom_bar(stat = "identity", aes(x = date, y = delayes, color = 'Late flights (departure delayed > 15 minutes)')) + 
  theme(legend.position = "bottom") + scale_color_manual(name = "Colors", values = c('All flights (schedualed for separtue)' = "blue", 'Late flights (departure delayed > 15 minutes)' = "red")) + 
  labs(title = "Weekly Cycles: Flights from NYC airports in 2013 \n  Few flights: Sundays & Saturdays \n Most Flights: Mondays, thursdays & fridays", y = "Flights per day") + 
  theme(plot.title = element_text(hjust = 0.5))
```

seif b
first we will make a table that include the subset of delayed flights alone and group this by destinations to get a cout of delayed flights by destinations.
simelarly, for refrence we will group the flights data by destinations to get a count of flights per destination. 
```{r}
# > 15 min. delay
delays <- subset(flights, dep_delay > 15)
del_dest_count <- table(delays$dest)
dest_overall <- table(flights$dest)
```

We can see that we have 3 airports withot delays at all:
```{r}
dest_overall[!(names(table(flights$dest)) %in% names(table(delays$dest)))]
```
So we'll ignore them and then assign them manually 0% (so we dint have deviding by 0 problems and such)
```{r}
no_del <- rownames(dest_overall[!(names(table(flights$dest)) %in% names(table(delays$dest)))])
dest_overall <- dest_overall[names(table(flights$dest)) %in% names(table(delays$dest))]
# compute percentages of dealyed for each dest
perc_delays <- as.data.frame(del_dest_count / dest_overall, row.names = TRUE)

# append and assign
to_append <- data.frame(rep(0,3))
colnames(to_append) <- 'Freq'
rownames(to_append) <- no_del
perc_delays <- rbind(perc_delays,to_append)
```
Now we hve the percentages, we will split the data in to bind by the delay time
```{r}
perc_delays$bin = cut(perc_delays$Freq, 
                  c(0,0.1,0.15,0.20,0.25,1), right = FALSE, 
                  labels=c("<= 10%",
                           "10% - 15%",
                           "15% - 20%",
                           "15% - 25%",
                           "> 25%"))
#for simplicity we'll define JFK as the source (all 3 are pretty close in output graph)
perc_delays[,c('lon_source','lat_source')] <- subset(airports, faa=='JFK', select = c('lon','lat'))
```
during getting target coordinates, we discovered 4 airports which don't have coordinated in the airports dataframe:
```{r}
rownames(perc_delays)[!(rownames(perc_delays) %in% airports$faa)]
```
All 4 of these airports are in puerto rico, so we will consider these as outliers and remove them (as done in the original graph)

```{r}
perc_delays <- perc_delays[rownames(perc_delays) %in% airports$faa,]
```
Now, it's possible to get the target coordinates
```{r}
perc_delays[,c('lon_target','lat_target')] <- airports[airports$faa %in% rownames(perc_delays),c('lon','lat')]
```
So wev'e done all the data procesing, now we jsut need to do the graphing.
first we need to get the USA with states to plot the rutes, for this we have a map in R, to add the state names we found a csv file with all the states name, acronyme and coodinates.
```{r message=FALSE, warning=FALSE}
USA <- subset(map_data("world"), region=="USA")
states <- read_csv("states.csv") # state name with location
```

now we can add the data to the map we have

```{r}
plot <- 
  ggplot() +
  # plot usa with state borders and names
  geom_polygon(data = USA, aes(x=long, y = lat, group = group), fill="white", alpha=0.3) +
  borders("state") +
  geom_text(aes(x=longitude,y=latitude, label=state), data=states, size = 2) +
# plot filghts according to delays
geom_segment(data = perc_delays, aes(x=lon_source,y=lat_source, xend=lon_target, yend=lat_target, colour=bin)) +
geom_point(data=perc_delays,aes(x=lon_target,y=lat_target, colour=bin),shape=21,size=1.5, show.legend = FALSE) +
scale_fill_manual(values=rep("white",5)) + 
scale_colour_manual(values=c("forestgreen", "purple", "blue","orange","red"))
```
We have out map now, but is scaled horibly so we need to fix that by setting limits and add some finishing touches .
```{r warning=FALSE}
plot +
  ggtitle("% of Flights Departures Delayed > 15 Min", subtitle = "airport=NY's airports    Year=2013") +
  theme(legend.title = element_blank(), legend.position = c(0.22,0.1), panel.background = element_blank(), axis.line = element_blank(), axis.title = element_blank(), axis.ticks = element_blank(), axis.text = element_blank(),legend.text = element_text(size=7), legend.key = element_rect(fill = "transparent", colour = "transparent"), legend.key.height = unit(0.7,"line"), plot.title = element_text(hjust = 0.5, size=10, face="bold"), plot.subtitle = element_text(hjust = 0.5, size=6, face="bold")) +
    xlim(-130,-70) + 
    ylim(25,50) +
    coord_map()
```


Q 4:
To have our graphical lineup, first we need to produce the grpah on the real data!
se we'll add (again) a binary colomn that gets a 1 when a fligth departure delay is longer then 15 mins and a 0 otherwise. 
then we'll see what rate of flights were delayed per month. 

```{r}
flights$date <-  as.POSIXct(flights$time_hour, "%m-%d-%Y")
flights$is_delayed <- ifelse(flights$dep_delay > 15, 1, 0)
monthly_avg_delay <- flights %>%
  select(month, is_delayed) %>%
  group_by(month) %>%
  summarise(average_delay <- mean(is_delayed, na.rm = 1) , sd(is_delayed, na.rm = 1)) %>%
  ungroup()
colnames(monthly_avg_delay) <- c("month", "delay_rate", "std")
```

Now we have our data, all we need to do is graph it:

```{r}
ggplot(monthly_avg_delay, aes(x = month, y = delay_rate)) + 
  geom_point(color = "red") + 
  geom_line(color = "blue") + 
  ylim(0,.5) + scale_x_continuous(breaks = c(1:12), labels = c("Jan","Feb","Mar","Apr", "May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")) +
  labs(title = "Delay rate of flights by month", x = "month", y = "% of delayed flights") + 
  theme(plot.title = element_text(hjust = 0.5))

```
Now we have our real data, let's simulate graphs based on the null hypothesis.
Our null hypothesis is that the average flight delay may change per month, but varies randomly across the year.
We decided to test this null hypothesis by simulating the delay rate.
We decided to examine 2 distrebutions for this. First we tried the Normal distrebution with the mean = the mean delay rate and STD = the STD of the monthly averages, we did this thinking that this will give us rates in the same order of magnitude of the real rates, but not bounded by our actual resalts, the disedvantige is the the simulated rates are not at all bounded at, so theoritcaly we can get "rates" higher than 1 or lower than 0.
Then we checked simulated results using the unform distrebutoin between the max and min real rates, the advantege here is that we know that all the simulated rates willl be pluasible, however this restricts the rates we can get and therfore eleminates some thoritcally possible (and even plausible) values.

```{r message=FALSE, warning=FALSE}
avg <- mean(flights$is_delayed, na.rm = TRUE)
std <- sd(monthly_avg_delay$delay_rate ,na.rm = TRUE)
set.seed(770)
ggplot(lineup(null_dist('delay_rate',dist = "norm",list(avg,std)),monthly_avg_delay), aes(factor(month))) +
  geom_line(aes(x=month,y=delay_rate), stat = 'identity', color = 'blue') +
  geom_point(aes(x=month,y=delay_rate), color = 'red') +
  ylim(0,.5) + scale_x_continuous(breaks = c(1:12), labels = c(1:12)) +
  labs(title = 'Norm Line-up Simulated Delay Rates', x = 'month', y = '% of dealyed flights') + 
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~ .sample)
```
The second one will be from a uniform dist with params: (minimum delay perc. of month, minimum delay perc. of month)
```{r message=FALSE, warning=FALSE}
min_rate <- min(monthly_avg_delay$delay_rate)
max_rate <- max(monthly_avg_delay$delay_rate)
set.seed(770)
ggplot(lineup(null_dist('delay_rate',dist = "unif",list(min_rate,max_rate)),monthly_avg_delay), aes(factor(month))) +
  geom_line(aes(x=month,y=delay_rate), stat = 'identity', color = 'blue') +
  geom_point(aes(x=month,y=delay_rate), color = 'red') +
  ylim(0,.5) + scale_x_continuous(breaks = c(1:12), labels = c(1:12)) +
  labs(title = 'Uniform Line-up Simulated Delay Rates', x = 'month', y = '% of dealyed flights') + 
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~ .sample)
```
Looking at both linups it is deffinatly hard to point at a single graph and decide that that is the one made from the real data. However with a clos einspection we can see that most graphs are very "bumpy" while a few are smoother. This Makes suspect that one of the smoother graphs may be the "real one" sinse it shows corelation between different months (as apose to the null hypothesis).
The problem is that in both linups, we have other graphs, besides the original, that are quite smooth, to an axtent that makes it hard to decide for sure witch one is real. 
We happen to know that the "real"graph is #10, howevewr in the normal linup #16 & #12 also stand out, so it would deffinatly be hard to pick the right one. similarly in the uniform line up #19 also stand out, as well as some other options. 
All in all in seems that it would be very hard to pass this line-up and therfore we shouldn't reject the null hypothesis.